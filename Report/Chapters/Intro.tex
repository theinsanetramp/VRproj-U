\chapter{Introduction}
\lhead{\emph{Introduction}}

There are many areas of science and engineering that require the observation of, and interaction with, environments not suitable for human beings. These environments are instead observed using teleoperated robots, potentially completely removing the need to put people in any danger. However, a challenge presented by telerobotics is giving the operator sufficient information about the robot's surroundings to give them a feeling of presence \cite{presence} within the space; this is essential for effective manoeuvring and interaction.

Virtual Reality (VR) is a technology that has proven itself to be able to provide the user with unparalleled presence within a virtual space- comparable to presence within a real, physical space \cite{loomis2016presence,McGlynn}. To be able to incorporate VR into teleoperation is therefore desirable. While this has been successfully attempted for the purpose of controlling robots within an already mapped space \cite{bounds2016integrated}, there has been much less success in exploring an unknown space through a VR interface. This is due to the high frame rate and low latency required to prevent motion sickness while in a VR environment.

It's widely accepted that for a VR application to not cause motion sickness and headaches due to frame rate, it must maintain at least 90 frames per second (fps) \cite{FrameRate}; a minimum of 60 fps can also be acceptable \cite{Borg2013UsingAG}, but generally only for applications with little motion or when used by people with lower susceptibility to motion sickness. Unfortunately, to transmit 90 fps from a stereo camera rig (two images are required to perceive 3D) to the computer running the VR application has very high bandwidth requirements. Also, a major factor in providing presence to the user in VR is their ability to look around the space independently. This can be achieved by mounting the stereo camera rig on a gimble, however to build a gimble that is able to track the angle of the user's head accurately and with low latency is both expensive and challenging \cite{DORA}; if not implemented perfectly the user would be more likely to suffer sickness and dissociation from the space than if the gimble was not used at all.

The aim of this project was to design and implement a VR based teleoperation system that utilises data abstraction and inter-frame interpolation to minimise the outlined technical issues, providing increased comfort and therefore presence to the user than otherwise possible. Data abstraction would be used in the robot to reduce each image down to its most essential features, reducing its size and therefore the required data rate significantly. Each image pair would then transmitted to a server and combined into a single 3D map of the space that could be looked around freely through the VR headset. As the camera feed would be viewed as a 3D environment rather than directly as images, the headset could run at the full 90fps even if the environment is updating at a much slower rate. As previously suggested, a camera gimble would track the movement of the headset, but it would not have to be very accurate as it would only updating the 3D map and not affect the headset directly.

The system would be realised using off-the-shelf VR equipment, a camera gimble adapted from one produced by previous students \cite{gimble}, and a simple rover that I would also building.