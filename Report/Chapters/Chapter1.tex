\chapter{Introduction}
\lhead{\emph{Introduction}}

There are many areas of science and engineering that require the observation of, and interaction with, environments not suitable for human beings. These environments are instead observed using teleoperated robots, potentially completely removing the need to put people in any danger. However, a challenge presented by telerobotics is giving the operator sufficient information about the robot's surroundings to give them a feeling of presence \cite{presence} within the space, allowing for effective manoeuvring and interaction.

Virtual Reality (VR) is a technology that has proven itself to be able to provide the user with unparalleled presence within a virtual space- comparable to presence within a real, physical space \cite{loomis2016presence}. To be able to incorporate VR into teleoperation is therefore desirable. While this has been successfully attempted for the purpose of control within an already known space \cite{bounds2016integrated}, there has been much less success in exploring an unknown space through a VR interface. This is due to the high frame rate and low latency required to prevent motion sickness while in a VR environment.

It's widely accepted that for a VR application to not cause motion sickness and headaches due to frame rate, it must maintain at least 90 frames per second (fps) \cite{FrameRate}; a minimum of 60 fps can also be acceptable, but generally only for applications with little motion or when used by people with lower susceptibility to motion sickness. Unfortunately, to transmit 90 fps from a stereo camera rig (two images are required to perceive 3D) to the computer running the VR application has very high bandwidth requirements. Also, a major factor in providing presence to the user in VR is their ability to look around the space independently. This can be achieved by mounting the stereo camera rig on a gimble, however for the gimble to track the angle of the user's head accurately and with low latency would be very challenging; the user would be more likely to suffer sickness and dissociation from the space than if the gimble was not used at all.

The aim of this project is to design and implement a VR based teleoperation system that utilises data abstraction and inter-frame interpolation to minimise the outlined technical issues, providing increased comfort and therefore presence to the user than otherwise possible. Data abstraction must be used in the robot to reduce each image down to its most essential features, reducing its size and therefore the required data rate significantly. Data rate must be further reduced by taking images at a low frame rate, such as 10 fps, and then increasing it up to 90 fps on the computer using inter-frame interpolation methods. Although this process will be based on interpolation methods, the frames will be extrapolated from optical flow based predictions so as to not increase latency. Each image pair must be finally be combined into a single 3D map of the space that can be looked around freely through the VR headset. As previously suggested, the camera gimble will track the movement of the headset, but it does not have to be very accurate as it is only updating the 3D map and not affecting the headset directly.

The system will be realised using off-the-shelf VR equipment, a camera gimble produced by previous students \cite{gimble}, and a simple rover that I am also building. This progress report will be focused on the progress made in data abstraction, so will not be covering the other aspects of the project other than to put the abstraction in context.